## Требования

*   **Go:** Версия 1.20 или новее.

## Сборка

Приложение можно собрать с помощью стандартной команды Go или используя предоставленный `Makefile`:

**С использованием Makefile:**
```bash
make build
```

**Напрямую:**
```bash
go build -o proxy *.go
```

## Конфигурация

Работа прокси управляется через YAML-файл конфигурации. По умолчанию приложение ищет файл `config.yaml` в текущей директории. Путь к файлу можно указать с помощью флага `-config`.

Ключевые секции конфигурации:

*   `log_level`: уровень логирования ("trace", "debug", "info", "warn", "error").
*   `udp_read_buffer_size`: размер буфера чтения UDP (в байтах). Влияет на максимальный размер принимаемого UDP-пакета. Должен быть в диапазоне [64, 65507].
*   `flow_timeout`: глобальный таймаут неактивности потока по умолчанию (формат Go Duration, например "60s").
*   `min_channel_size`, `max_channel_size`: глобальные лимиты для размера внутреннего канала пакетов маршрута.
*   `cleaner_settings`: настройки для механизма очистки неактивных потоков (интервалы, делитель).
*   `defaults`: значения по умолчанию для параметров маршрутов (`flow_timeout`, `workers`, `chan_size`).
*   `streams`: список правил маршрутизации. Каждое правило определяет:
    *   `name`: имя маршрута (для логов).
    *   `listen_address`: локальный адрес и порт для приема трафика от клиентов.
    *   `source_address`: адрес и порт вышестоящего источника данных.
    *   `flow_timeout`, `workers`, `chan_size`: опциональные параметры, переопределяющие значения из `defaults`.

**Пример `config.yaml`:**

```yaml
# Уровень логирования: "trace", "debug", "info", "warn", "error"
# По умолчанию: "info"
log_level: "debug"

# --- Глобальные настройки по умолчанию ---

# Размер буфера для чтения UDP пакетов в байтах
# Должен быть в диапазоне [64, 65507]
# Если не указан, используется значение по умолчанию из кода (2048)
udp_read_buffer_size: 4096

# Таймаут неактивности потока по умолчанию (если не переопределен в defaults или stream)
# Используйте формат Go Duration ("60s", "5m", "1h")
# Если не указан, используется абсолютный дефолт (60s)
flow_timeout: "90s"

# Минимальный размер канала пакетов для маршрутов
# Если chan_size маршрута меньше этого значения, будет использовано это значение
# По умолчанию в коде 64
min_channel_size: 128

# Максимальный размер канала пакетов для маршрутов
# Если chan_size маршрута больше этого значения, будет использовано это значение
# По умолчанию в коде 8192
max_channel_size: 8192

# --- Настройки Cleaner'а ---
cleaner_settings:
  # Базовый интервал проверки, используется если нет активных потоков с таймаутом
  # Также является максимальным значением, если вычисленный интервал его превышает
  # Должен быть >= min_interval
  base_interval: "10s"

  # Минимальный интервал между запусками cleaner'а
  # Вычисленный интервал (min_route_timeout / interval_divisor) не будет меньше этого
  min_interval: "2s"

  # Максимальный интервал между запусками cleaner'а
  # Вычисленный интервал не будет больше этого. Должен быть >= base_interval
  max_interval: "200s"

  # Делитель для расчета интервала cleaner'а на основе минимального активного таймаута маршрута
  # interval = min_route_timeout / interval_divisor (ограниченный min/max_interval)
  # Должен быть > 0
  # При 1 интервал очистки будет равен минимальнному flow_timeout, но в границах min_interval и max_interval
  interval_divisor: 1

# --- Значения по умолчанию для секции streams ---
# Эти значения используются для маршрутов, если они не указаны явно в самом маршруте
defaults:
  # Таймаут неактивности для потоков (переопределяет глобальный flow_timeout)
  flow_timeout: "60s"

  # Количество горутин-воркеров для обработки пакетов маршрута
  # Должно быть в диапазоне [1, 128]
  workers: 8

  # Размер канала для передачи пакетов от листенера к воркерам
  # Будет ограничен глобальными min_channel_size и max_channel_size
  chan_size: 1024

# --- Список правил маршрутизации потоков ---
streams:
  - name: "Stream-A" # Имя маршрута
    listen_address: ":9001" # Локальный адрес:порт для приема от клиента
    source_address: "10.0.2.200:9002" # Адрес:порт источника данных
    flow_timeout: "30s" # Переопределяем flow_timeout из defaults
    workers: 12 # Переопределяем workers из defaults
    chan_size: 2048 # Переопределяем chan_size из defaults

  - name: "Stream-B"
    listen_address: ":9003"
    source_address: "192.168.60.156:9004"
    # Используем workers и chan_size из defaults
    flow_timeout: "45s"

  - name: "Stream-C"
    listen_address: ":9005"
    source_address: "192.168.60.156:9006"
    workers: 12
    chan_size: 2048
    # Используем flow_timeout из defaults ("60s")
```

## Запуск

Запустите собранный исполняемый файл, указав путь к файлу конфигурации (если он отличается от `config.yaml`):

```bash
./proxy -config /путь/к/вашему/config.yaml
```

Или используйте `Makefile` для запуска с `config.yaml` по умолчанию:
```bash
make run
```
Для запуска с другим конфигом через Makefile:
```bash
make run-config CONFIG=/путь/к/вашему/config.yaml
```

Приложение будет работать до получения сигнала `SIGINT` или `SIGTERM` (например, при нажатии `Ctrl+C`), после чего попытается выполнить завершение работы.

## Принцип работы и внутренние механизмы

Данный прокси реализует логику перенаправления UDP-потоков с возможностью логирования SRT и динамического управления соединениями.

### Инициализация и конфигурация

Запуск приложения начинается в функции `main` (`main.go`). Первым шагом является обработка флагов командной строки для определения пути к файлу конфигурации (по умолчанию `config.yaml`). Затем происходит первоначальная загрузка конфигурации с помощью `LoadConfig` (`config.go`). Эта функция читает YAML-файл, десериализует его в структуру `Config` и выполняет базовую валидацию, например, проверку на дублирующиеся адреса прослушивания (`listen_address`) в определениях маршрутов (`streams`). Структура `Config` содержит глобальные настройки (уровень логирования, таймаут потока по умолчанию, настройки cleaner'а, лимиты размера канала, размер буфера чтения UDP), секцию `defaults` для общих параметров маршрутов и список самих маршрутов (`streams`), каждый из которых определяет имя, адрес прослушивания, адрес целевого источника и специфичные для маршрута настройки (таймаут, количество воркеров, размер канала).

После успешной загрузки конфигурации настраивается глобальный логгер (`log` типа `logrus.Logger`) с помощью `SetupLogger` (`logger.go`), используя уровень логирования из конфигурации. С этого момента все компоненты приложения могут использовать настроенный логгер.

Далее создается экземпляр `ProxyServer` (`proxy.go`), который является центральным компонентом, управляющим всеми маршрутами и глобальными процессами. В `ProxyServer` передается глобальный `context.Context`, который используется для сигнализации о завершении работы всего приложения.

### Запуск прокси и маршрутов

Вызов `proxyServer.Start` инициирует основную работу. Внутри `Start` сначала применяются глобальные настройки из загруженной конфигурации:

1.  Параметры для Cleaner'а (интервалы проверки, делитель) обновляются через `updateCleanerSettings`.
2.  Глобальные лимиты для размеров каналов пакетов (`min_channel_size`, `max_channel_size`) устанавливаются через `updateChannelSizeLimits`. Эти лимиты будут использоваться при разрешении `chan_size` для каждого маршрута.
3.  Глобальный размер буфера для чтения UDP-пакетов настраивается через `resolveAndUpdateUDPReadBufferSize`. Эта функция валидирует значение `udp_read_buffer_size` из конфига, применяет дефолты и ограничения (`MinUDPReadBufferSize`, `MaxUDPPayloadSize`), а затем вызывает `SetEffectiveUDPReadBufferSize` (`buffers.go`). `SetEffectiveUDPReadBufferSize` атомарно обновляет глобальную переменную `currentUDPReadBufferSize` (типа `atomic.Int32`), делая новый размер немедленно доступным для всех частей приложения, использующих буферы.

Затем `ProxyServer` валидирует и разрешает определения маршрутов из конфигурации (`validateAndResolveNewConfig`). Для каждого валидного маршрута разрешаются адреса, таймаут (`parseTimeout` из `utils.go` с учетом глобального и абсолютного дефолта), количество воркеров (`resolveWorkerCount` с учетом дефолтов и лимитов) и размер канала (`resolveChannelSize` с учетом дефолтов и эффективных глобальных лимитов).

Для каждого разрешенного маршрута вызывается `startRouteLocked`. Эта функция создает экземпляр `ActiveRoute` (`route.go`). `ActiveRoute` отвечает за один конкретный маршрут (один `listen_address`). При создании `ActiveRoute` открывается основной UDP-сокет (`net.ListenUDP`) на указанном `listen_address`. Создается канал `packetChan` заданного размера для передачи пакетов от листенера к воркерам. Далее вызывается `activeRoute.startProcessing`, который запускает две основные группы горутин для этого маршрута:

*   Одну горутину `clientListenerLoop`: она непрерывно читает UDP-пакеты с основного сокета (`listener.ReadFromUDP`).
*   Пул горутин-воркеров (`packetWorker`): их количество определяется параметром `workers`. Они ожидают пакеты из `packetChan`.

После запуска всех валидных маршрутов, `ProxyServer.Start` запускает фоновую горутину `flowCleanerLoop` (`cleaner.go`), отвечающую за периодическую очистку неактивных потоков.

### Обработка трафика (Клиент -> Источник)

Когда клиент отправляет UDP-пакет на `listen_address` одного из активных маршрутов, горутина `clientListenerLoop` этого маршрута читает его с помощью `listener.ReadFromUDP`. Перед чтением она получает буфер из пула с помощью `getPacketBuffer` (`buffers.go`). Эта функция использует два пула `sync.Pool`: один (`packetBufferPool`) для структур `packetBuffer` (содержащих метаданные пакета) и другой (`udpBufferPool`) для базовых срезов байтов (`[]byte`), в которые читаются данные. `getPacketBuffer` извлекает структуру и указатель на срез из пулов. Важно, что она проверяет `cap()` (емкость) полученного среза байтов на соответствие текущему глобальному размеру `currentUDPReadBufferSize`. Если емкость не совпадает (например, размер буфера был изменен через перезагрузку конфигурации), старый срез отбрасывается и выделяется новый срез правильного текущего размера. Это обеспечивает адаптацию к изменениям `udp_read_buffer_size` "на лету". Если емкость совпадает, срез из пула используется повторно. Поле `pb.Data` в `packetBuffer` устанавливается так, чтобы оно указывало на весь выделенный срез байтов (`pb.buffer[:cap(pb.buffer)]`), готовя его к чтению данных.

Прочитанный пакет (данные, размер `n` и адрес клиента `remoteAddr`) упаковывается в `packetBuffer` (поля `N` и `RemoteAddr` заполняются) и отправляется в `packetChan` маршрута. Если канал переполнен (воркеры не успевают обрабатывать), пакет отбрасывается с соответствующим логом.

Одна из свободных горутин `packetWorker` получает `packetBuffer` из канала. Она вызывает `handleClientPacket`, передавая буфер. После того как `handleClientPacket` завершит обработку, воркер возвращает буфер обратно в пулы с помощью `putPacketBuffer` (подробнее см. секцию "Управление Буферами и Памятью").

`handleClientPacket` является ядром логики маршрутизации потоков. Она использует адрес клиента (`pb.RemoteAddr`) как ключ для поиска в `clientFlows` (`sync.Map`) маршрута.

*   **Если поток найден:** вызывается `processPacketForExistingFlow`. Эта функция проверяет, не остановлен ли уже поток (через его контекст). Если активен, она атомарно обновляет временную метку последней активности потока (`flow.lastActivity.Store`) и отправляет данные пакета (`pb.Data[:pb.N]`) вышестоящему источнику через уже существующее, выделенное для этого потока UDP-соединение (`flow.outConn.Write`). Обрабатываются ошибки записи, такие как разрыв соединения (`syscall.EPIPE`, `ECONNREFUSED`), которые приводят к остановке потока (`flow.Stop`).
*   **Если поток не найден:** вызывается `createNewFlowAndProcessPacket`. Эта функция инициирует создание нового потока:
    1.  Устанавливается UDP-соединение с целевым источником (`net.DialUDP`), что приводит к выделению локального эфемерного порта на стороне прокси для этого конкретного потока.
    2.  Создается структура `ClientFlow` (`clientflow.go`), содержащая адреса клиента и источника, созданное соединение `outConn`, атомарную переменную `lastActivity`, собственный `context.Context` (дочерний от контекста маршрута) и функцию `cancel` для него, `sync.WaitGroup` (`flowWg`), ссылку на основной `listener` маршрута и конфигурационные параметры (имя, таймаут).
    3.  С помощью `clientFlows.LoadOrStore` структура `ClientFlow` атомарно помещается в карту. Этот метод позволяет корректно обработать гонку, если несколько воркеров одновременно пытаются создать поток для одного и того же клиента: только один воркер успешно сохранит поток, остальные получат ссылку на уже созданный.
    4.  Если воркер успешно создал и сохранил поток (`loaded == false`), он запускает для этого потока горутину `reverseListenerLoop` (см. ниже) и отправляет первый пакет клиента источнику через `newFlow.outConn.Write`. Если произошла ошибка при первой записи, поток считается нежизнеспособным, немедленно удаляется из карты и останавливается (`newFlow.Stop`).
    5.  Если `LoadOrStore` показал, что поток уже был создан другим воркером (`loaded == true`), текущий воркер закрывает созданное им (теперь избыточное) соединение `outConn`, отменяет созданный им контекст и делегирует отправку текущего пакета функции `processPacketForExistingFlow`, используя поток, полученный из карты.

### Обработка трафика (Источник -> Клиент)

Для каждого активного `ClientFlow` работает горутина `reverseListenerLoop`. Она блокирующе читает данные (`flow.outConn.Read`) из соединения, установленного с источником (`flow.outConn`). Перед чтением она также получает буфер через `getPacketBuffer`. При получении пакета она обновляет `flow.lastActivity` потока и затем отправляет данные исходному клиенту (`flow.clientAddr`) используя основной слушающий сокет маршрута (`ar.listener.WriteToUDP`). Перед отправкой проверяется контекст потока (`flow.flowCtx`) на случай отмены. Ошибки записи клиенту обрабатываются; например, ошибки `EPIPE`, `ECONNREFUSED`, `ENETUNREACH` указывают на недоступность клиента и приводят к остановке потока (`flow.Stop`). После отправки (или при ошибке) буфер возвращается через `putPacketBuffer`. Горутина `reverseListenerLoop` завершается штатно, когда `flow.outConn` закрывается (при `flow.Stop`), что приводит к ошибке `net.ErrClosed` при чтении.

### Управление жизненным циклом потоков и Cleaner

Каждый `ClientFlow` имеет таймаут неактивности (`flowTimeout`), унаследованный от настроек маршрута при создании. `ProxyServer` запускает `flowCleanerLoop`, которая работает в отдельной горутине. Внутри цикла cleaner'а:

1.  Периодически (с интервалом `currentInterval`) вызывается `cleanupClientFlows`.
2.  `cleanupClientFlows` конкурентно (по одной горутине на маршрут) обходит все активные маршруты и их `clientFlows` (`sync.Map.Range`).
3.  Для каждого потока проверяется время последней активности (`flow.lastActivity.Load()`). Если `time.Now().UnixNano() - lastActivityNanos > flowTimeout.Nanoseconds()`, поток считается неактивным.
4.  Неактивный поток атомарно удаляется из карты `clientFlows` с помощью `LoadAndDelete`.
5.  Для удаленного потока асинхронно вызывается `flow.Stop()`.
6.  `flow.Stop` отменяет контекст потока (`flow.flowCancel()`), закрывает исходящее соединение `outConn` (что приводит к завершению `reverseListenerLoop`) и ожидает завершения горутины `reverseListenerLoop` с помощью `flow.flowWg.Wait()`.

Интервал работы `flowCleanerLoop` (`currentInterval`) динамически адаптируется. После каждого цикла очистки он пересчитывается: находится минимальный положительный `flowTimeout` среди всех активных маршрутов. Новый интервал вычисляется как `minTimeout / cleanerIntervalDivisor` и ограничивается значениями `cleanerMinInterval` и `cleanerMaxInterval` (все эти параметры берутся из текущей конфигурации `ProxyServer` под блокировкой `cleanerConfigLock`). Если вычисленный интервал отличается от текущего, тикер перенастраивается (`ticker.Reset`). Это позволяет cleaner'у работать чаще, если есть потоки с короткими таймаутами, и реже в противном случае.

### Динамическая перезагрузка конфигурации

В `main` запускается горутина с `fsnotify` для наблюдения за изменениями в директории конфигурационного файла. При обнаружении событий записи/создания/переименования файла конфигурации запускается таймер дебаунсинга (`configReloadDebounce`). По истечении таймера запрос на перезагрузку отправляется через канал `reloadRequest`. Основной цикл `main` получает запрос, снова вызывает `LoadConfig` для загрузки нового файла. Если загрузка успешна, вызывается `proxyServer.Reload`.

`proxyServer.Reload` выполняет следующие шаги под глобальной блокировкой `routesLock`:

1.  Обновляет глобальные настройки (cleaner, лимиты каналов, размер UDP-буфера) так же, как при `Start`.
2.  Разрешает маршруты из новой конфигурации (`validateAndResolveNewConfig`).
3.  Сравнивает текущий набор активных маршрутов с новым. Маршруты, отсутствующие в новой конфигурации, останавливаются (`stopRemovedRoutesLocked` вызывает `activeRoute.Stop` для каждого).
4.  Обрабатывает новые и обновленные маршруты (`processNewAndUpdatedRoutesLocked`):
    *   Если маршрут с таким `listen_address` появился в новой конфигурации, а раньше его не было, он запускается (`startRouteLocked`).
    *   Если маршрут существовал, сравниваются его параметры. Если изменился `source_address` или `workers`, старый маршрут останавливается (`activeRoute.Stop`), а затем запускается новый с теми же `listen_address`, но новыми параметрами. Если изменились только `name` или `flow_timeout`, они обновляются "на лету" (`updateRouteInPlaceLocked`) без перезапуска маршрута, путем модификации полей в `ActiveRoute` под блокировкой `activeRoute.configLock`. Изменение `chan_size` в текущей реализации само по себе не приводит к перезапуску, но будет применено при перезапуске по другой причине.
5.  После успешного `Reload` в `main` также обновляется уровень логгирования, если он изменился в конфигурации.

### Влияние изменений конфигурации на соединения при перезагрузке

Не все изменения конфигурации могут быть применены без разрыва существующих UDP-потоков.

**Изменения, приводящие к сбросу соединений на затронутых маршрутах:**

*   `listen_address`: удаляет старый маршрут и создает новый. Все потоки старого маршрута останавливаются.
*   `source_address`: требует полного перезапуска маршрута. Старый `ActiveRoute` останавливается, запускается новый.
*   `workers`: требует перезапуска `ActiveRoute`, все текущие потоки останавливаются.

**Изменения, применяемые "на лету" без сброса соединений на затронутых маршрутах:**

*   `name`: обновляется в `ActiveRoute` без влияния на потоки.
*   `flow_timeout`: новое значение используется Cleaner'ом при следующей проверке и для новых потоков. Существующие потоки не разрываются немедленно.
*   `chan_size`: новый размер применяется только при перезапуске маршрута по другим причинам (`source_address`, `workers`).
*   `log_level` (глобальный): применяется немедленно ко всему приложению.
*   `cleaner_settings` (глобальные): влияют на логику очистки, но не на установленные потоки.
*   `min_channel_size`, `max_channel_size` (глобальные): применяются при разрешении конфигурации для новых/перезапускаемых маршрутов.
*   `udp_read_buffer_size` (глобальный): обновляется атомарно и используется для последующих операций чтения без прерывания потоков.

### Логирование SRT-пакетов

Для облегчения диагностики проблем, связанных с протоколом SRT, прокси включает механизм логирования SRT-пакетов в `logSRTPacket` (`utils.go`).

*   **Активация:** логирование SRT активно, только если `log_level` установлен на `debug` или `trace`.
*   **Механизм:** используется библиотека `github.com/datarhei/gosrt/packet` для разбора UDP-пейлоада.
*   **Детализация:**
    *   **Handshake (`CTRLTYPE_HANDSHAKE`):** тип рукопожатия (`INDUCTION`, `CONCLUSION` и т.д.) логируется на уровне `debug`. Технические детали (версия, SYN cookie и т.д.) — на `trace`.
    *   **Shutdown (`CTRLTYPE_SHUTDOWN`):** описательное сообщение логируется на `debug`. Технические детали — на `trace`.
    *   **Другие управляющие пакеты (Keepalive, ACK, NAK и т.д.):**  логируются на уровне `trace`.
    *   **Пакеты данных:** логируются на уровне `trace`.
*   **Контекст:** в логах указывается имя маршрута, направление (Sending/Received), адрес удаленной стороны, локальный сокет и размер пакета.


### Завершение работы

При получении сигнала `SIGINT` или `SIGTERM`, `main` вызывает `globalCancel()`, отменяя глобальный контекст. Это сигнализирует всем компонентам о необходимости завершения. Вызывается `proxyServer.Stop()`, который инициирует остановку всех активных маршрутов (`activeRoute.Stop` для каждого) и дожидается завершения cleaner'а (`cleanerWg.Wait`). `activeRoute.Stop` каскадно останавливает листенер, воркеров и все связанные `ClientFlow`. После остановки `ProxyServer`, `main` дожидается завершения горутины файлового наблюдателя (`wg.Wait`) и завершает работу.

### Управление буферами и памятью

Для минимизации выделения памяти и нагрузки на сборщик мусора (GC) прокси активно использует пулы объектов (`sync.Pool`):

*   **`udpBufferPool`:** хранит указатели на срезы байтов (`*[]byte`), используемые для чтения/записи UDP-данных.
*   **`packetBufferPool`:** хранит структуры `packetBuffer`, которые содержат срез данных и метаинформацию о пакете (размер, адрес отправителя).

Функция `getPacketBuffer` отвечает за получение буфера перед операцией чтения UDP. Она:
1.  Извлекает структуру `packetBuffer` из `packetBufferPool`.
2.  Извлекает указатель на срез байтов из `udpBufferPool`.
3.  **Проверяет емкость (`cap`)** среза байтов. Если она не соответствует текущему значению `currentUDPReadBufferSize` (установленному из конфигурации), то этот срез считается устаревшим (или nil), и **выделяется новый срез** нужного размера. Старый (если был) не возвращается в пул и будет собран GC.
4.  Если емкость совпадает, срез используется повторно.
5.  Структура `packetBuffer` подготавливается к использованию (сбрасываются поля `N`, `RemoteAddr`, полю `Data` присваивается ссылка на актуальный срез байтов).

Функция `putPacketBuffer` возвращает ресурсы обратно в пулы после использования:
1.  Сбрасывает поля `Data`, `RemoteAddr`, `N` в структуре `packetBuffer`.
2.  Если внутренний срез байтов (`pb.buffer`) не nil, указатель на него (`&pb.buffer`) возвращается в `udpBufferPool`.
3.  Сама структура `packetBuffer` возвращается в `packetBufferPool`.

### Makefile targets

Доступные цели в `Makefile`:

*   `make build`: собрать исполняемый файл.
*   `make run`: запустить прокси с файлом `config.yaml`.
*   `make run-config CONFIG=<path>`: запустить прокси с указанным файлом конфигурации.
*   `make clean`: удалить собранный бинарный файл.
*   `make tidy`: выполнить `go mod tidy`.